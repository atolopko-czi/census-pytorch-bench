c6id.16xlarge
64 vCPU, 128 Gib RAM, 2x1900 NVMe SSD
Local mirror of Census on SSD
Swap on SSD

- Throughput estimate

  Heart: 3100142 cells (4344062228 X values) in 262s:  11832 cells/sec
  Lung: 5976308 cells (9717102940 X values) in 1644s: 3635 cells/sec

  Heart, with no swapping, provides the high-end throughput potential. Lung
  with swapping observed, is 3x slower. With no swapping, iterating all Census 
  primary cells (~40M) should take ~1hr.

  Requires further investigation, since memory requirement should *not*
  increase for larger cell counts (due to streaming).

- PyTorch batch size: 128 (262s), 256 (257s), and 512 (244s), 1024 (473s)

  Modestly faster as bath size increases, until 1024, which is much
  slower. Should investigate the drop-off in performance for larger batch sizes.

- SOMA buffer bytes: 134217728 (265s), 268435456 (267s), 536870912 (263s)

  No apparent impact on run time with varying SOMA buffer bytes values. Should
  re-run with smaller values to see at what point an impact is observable.

- Sparse X tensors: sparse (148s) vs dense (262s) for heart; sparse (1623s) vs
  dense (1644) for lung

- Multiprocessing: 0 (262s), 2 (431s), 4 (284s), 8 (245s)

  Initially, slower for 2 and 4, with decreasing returns for 8, which finally
  outperforms single process. Multiprocessing does not provide a benefit.

- Eager fetch: eager (1644s) vs lazy fetch (2010s).

  Inconclusive since it ran on 'lung' tissue, which was fully retrieved in a
  single SOMA batch; need to re-run on query result that requires multiple
  SOMA batches

- Tissue sizes

  lung:   5976308 cells  (1644s,   8318306 major page faults)
  blood:  9429391 cells  (2555s,  22788989 major page faults)
  brain: 18548003 cells (15078s, 266099204 major page faults)

  Slower performance for larger data sizes, due to more page faults.

  Requires further investigation, since memory requirement should *not*
  increase for larger cell counts (due to streaming).
